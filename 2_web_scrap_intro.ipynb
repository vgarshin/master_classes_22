{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "simple-pilot",
   "metadata": {},
   "source": [
    "# Mastering Applied Skills in Management, Analytics and Entrepreneurship I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-giant",
   "metadata": {},
   "source": [
    "## DATA COLLECTION TECHNIQUES\n",
    "## Part III. Web scraping intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-wisdom",
   "metadata": {},
   "source": [
    "### 1. Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-rubber",
   "metadata": {},
   "source": [
    "Let's start from very basic example, we wiil need [urllib](https://docs.python.org/3/library/urllib.html) library for  opening and reading URLs. We will also use [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) Python library to parce HTML data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-directive",
   "metadata": {},
   "source": [
    "### 2. Get text from HTML page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_2_SCRAP = 'https://gsom.spbu.ru/en/programmes/graduate/miba/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = Request(URL_2_SCRAP)\n",
    "response = urlopen(request)\n",
    "html = response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = soup.text\n",
    "for ch in ['\\n', '\\t', '\\r']:\n",
    "    text = text.replace(ch, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-indianapolis",
   "metadata": {},
   "source": [
    "### 3. Simple NLP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower text and leave only text without symbols\n",
    "text = re.sub('[^а-яА-Яa-zA-Z]+', ' ', text).strip().lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_list = text.split()\n",
    "text_as_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(text_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = dict(Counter(text_as_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = dict(\n",
    "    sorted(\n",
    "        freqs.items(), \n",
    "        key=lambda item: item[1], \n",
    "        reverse=True\n",
    "    )\n",
    ")\n",
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_bar = {k: v for k, v in freqs.items() if v >= 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.bar(*zip(*freqs_bar.items()))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-integration",
   "metadata": {},
   "source": [
    "## <font color='red'>INTERMEDIATE QUIZ</font>\n",
    "Find the any site you like and do the folowing:\n",
    "1. Collect HTML page of any site you like\n",
    "2. Take the text from that page and process it\n",
    "3. Draw a word frequency plot and make a conclusion about the theme of the site (e.g. news, education, IT etc.)\n",
    "4. Find a few major drawbacks of that simple analysis based on word-count approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-bargain",
   "metadata": {},
   "source": [
    "### 4. Save HTML to disk as row data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('miba_page.html', 'w') as file:\n",
    "    file.write(html.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('miba_page.html', 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-investor",
   "metadata": {},
   "source": [
    "### 5. More than text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('img')[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('img', attrs={'alt': 'Vladimir Andreevich Gorovoy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('img', attrs={'alt': re.compile(r\".*Gorovoy\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('img')[20]['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_2_SCRAP = 'https://gsom.spbu.ru' + soup.find_all('img')[20]['src']\n",
    "print(URL_2_SCRAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = Request(URL_2_SCRAP)\n",
    "response = urlopen(request)\n",
    "img = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "img = Image.open(img)\n",
    "plt.imshow(np.array(img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.save('Vladimir.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-liquid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
